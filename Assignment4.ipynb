{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d85f767a",
   "metadata": {},
   "source": [
    "# Assignment 4 \n",
    "**Name:** Bhanavi\n",
    "**Roll No:** 102313054"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753da247",
   "metadata": {},
   "source": [
    "#### Q1. Write a Python program to scrape all available books from the website (https://books.toscrape.com/) Books to Scrape – a live site built for practicing scraping (safe, legal, no anti-bot). For each book, extract the following details: \n",
    "##### 1. Title \n",
    "##### 2. Price \n",
    "##### 3. Availability (In stock / Out of stock) \n",
    "##### 4. Star Rating (One, Two, Three, Four, Five) \n",
    "##### Store the scraped results into a Pandas DataFrame and export them to a CSV file named books.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c46ba903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://books.toscrape.com/\n",
      "Fetching: https://books.toscrape.com/catalogue/page-2.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-3.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-4.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-5.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-6.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-7.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-8.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-9.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-10.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-11.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-12.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-13.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-14.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-15.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-16.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-17.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-18.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-19.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-20.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-21.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-22.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-23.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-24.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-25.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-26.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-27.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-28.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-29.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-30.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-31.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-32.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-33.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-34.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-35.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-36.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-37.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-38.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-39.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-40.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-41.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-42.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-43.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-44.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-45.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-46.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-47.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-48.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-49.html\n",
      "Fetching: https://books.toscrape.com/catalogue/page-50.html\n",
      "Total books scraped: 1000\n",
      "Saved books.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "BASE = \"https://books.toscrape.com/\"\n",
    "\n",
    "def parse_book_block(article):\n",
    "    title = article.h3.a['title'].strip()\n",
    "    price = article.find(\"p\", class_=\"price_color\").text.strip()\n",
    "    availability = article.find(\"p\", class_=\"instock availability\").text.strip()\n",
    "    star_classes = article.find(\"p\", class_=\"star-rating\")['class']\n",
    "    star_rating = [c for c in star_classes if c != \"star-rating\"][0]\n",
    "    return {\"title\": title, \"price\": price, \"availability\": availability, \"star_rating\": star_rating}\n",
    "\n",
    "books = []\n",
    "next_page = \"catalogue/page-1.html\"  \n",
    "\n",
    "resp = requests.get(BASE)\n",
    "soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "\n",
    "page_url = BASE\n",
    "while True:\n",
    "    print(f\"Fetching: {page_url}\")\n",
    "    resp = requests.get(page_url)\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "\n",
    "    articles = soup.select(\"article.product_pod\")\n",
    "    for art in articles:\n",
    "        books.append(parse_book_block(art))\n",
    "\n",
    "    next_li = soup.select_one(\"li.next > a\")\n",
    "    if not next_li:\n",
    "        break\n",
    "    next_href = next_li['href']\n",
    "   \n",
    "    page_url = urljoin(page_url, next_href)\n",
    "    time.sleep(0.2) \n",
    "\n",
    "print(f\"Total books scraped: {len(books)}\")\n",
    "\n",
    "df = pd.DataFrame(books)\n",
    "df.to_csv(\"books.csv\", index=False)\n",
    "print(\"Saved books.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7f1f23",
   "metadata": {},
   "source": [
    "#### Q2. Write a Python program to scrape the IMDB Top 250 Movies list (https://www.imdb.com/chart/top/) . For each movie, extract the following details: \n",
    "##### 1. Rank (1–250) \n",
    "##### 2. Movie Title \n",
    "##### 3. Year of Release \n",
    "##### 4. IMDB Rating \n",
    "##### Store the results in a Pandas DataFrame and export it to a CSV file named imdb_top250.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6336bb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved imdb_top250.csv (rows: 0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "url = \"https://www.imdb.com/chart/top/\"\n",
    "driver.get(url)\n",
    "time.sleep(1.5)  \n",
    "\n",
    "rows = driver.find_elements(By.CSS_SELECTOR, \"table.chart.full-width tbody tr\")\n",
    "\n",
    "movies = []\n",
    "for idx, row in enumerate(rows, start=1):\n",
    "\n",
    "    rank = idx\n",
    " \n",
    "    title_elem = row.find_element(By.CSS_SELECTOR, \"td.titleColumn a\")\n",
    "    title = title_elem.text.strip()\n",
    "    year_elem = row.find_element(By.CSS_SELECTOR, \"td.titleColumn span.secondaryInfo\")\n",
    "    year_text = year_elem.text.strip()  # e.g., \"(1994)\"\n",
    "    \n",
    "    year = year_text.strip(\"()\")\n",
    "\n",
    "    rating_elem = row.find_element(By.CSS_SELECTOR, \"td.imdbRating strong\")\n",
    "    rating = rating_elem.text.strip()\n",
    "\n",
    "    movies.append({\"rank\": rank, \"title\": title, \"year\": year, \"imdb_rating\": rating})\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df = pd.DataFrame(movies)\n",
    "df.to_csv(\"imdb_top250.csv\", index=False)\n",
    "print(\"Saved imdb_top250.csv (rows: {})\".format(len(df)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb59b331",
   "metadata": {},
   "source": [
    "#### Q3. Write a Python program to scrape the weather information for top world cities from the given website (https://www.timeanddate.com/weather/) . For each city, extract the following details: \n",
    "##### 1. City Name \n",
    "##### 2. Temperature \n",
    "##### 3. Weather Condition (e.g., Clear, Cloudy, Rainy, etc.) \n",
    "##### Store the results in a Pandas DataFrame and export it to a CSV file named weather.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c475964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 142 candidate city links on index page\n",
      "[1/142] Fetching https://www.timeanddate.com/weather/india/patiala\n",
      "[2/142] Fetching https://www.timeanddate.com/weather/usa/new-york\n",
      "[3/142] Fetching https://www.timeanddate.com/weather/uk/london\n",
      "[4/142] Fetching https://www.timeanddate.com/weather/japan/tokyo\n",
      "[5/142] Fetching https://www.timeanddate.com/weather/ghana/accra\n",
      "[6/142] Fetching https://www.timeanddate.com/weather/malaysia/kuala-lumpur\n",
      "[7/142] Fetching https://www.timeanddate.com/weather/ethiopia/addis-ababa\n",
      "[8/142] Fetching https://www.timeanddate.com/weather/kuwait/kuwait-city\n",
      "[9/142] Fetching https://www.timeanddate.com/weather/australia/adelaide\n",
      "[10/142] Fetching https://www.timeanddate.com/weather/ukraine/kyiv\n",
      "[11/142] Fetching https://www.timeanddate.com/weather/algeria/algiers\n",
      "[12/142] Fetching https://www.timeanddate.com/weather/bolivia/la-paz\n",
      "[13/142] Fetching https://www.timeanddate.com/weather/kazakstan/almaty\n",
      "[14/142] Fetching https://www.timeanddate.com/weather/nigeria/lagos\n",
      "[15/142] Fetching https://www.timeanddate.com/weather/jordan/amman\n",
      "[16/142] Fetching https://www.timeanddate.com/weather/pakistan/lahore\n",
      "[17/142] Fetching https://www.timeanddate.com/weather/netherlands/amsterdam\n",
      "[18/142] Fetching https://www.timeanddate.com/weather/usa/las-vegas\n",
      "[19/142] Fetching https://www.timeanddate.com/weather/russia/anadyr\n",
      "[20/142] Fetching https://www.timeanddate.com/weather/peru/lima\n",
      "[21/142] Fetching https://www.timeanddate.com/weather/usa/anchorage\n",
      "[22/142] Fetching https://www.timeanddate.com/weather/portugal/lisbon\n",
      "[23/142] Fetching https://www.timeanddate.com/weather/turkey/ankara\n",
      "[24/142] Fetching https://www.timeanddate.com/weather/madagascar/antananarivo\n",
      "[25/142] Fetching https://www.timeanddate.com/weather/usa/los-angeles\n",
      "[26/142] Fetching https://www.timeanddate.com/weather/paraguay/asuncion\n",
      "[27/142] Fetching https://www.timeanddate.com/weather/spain/madrid\n",
      "[28/142] Fetching https://www.timeanddate.com/weather/greece/athens\n",
      "[29/142] Fetching https://www.timeanddate.com/weather/nicaragua/managua\n",
      "[30/142] Fetching https://www.timeanddate.com/weather/usa/atlanta\n",
      "[31/142] Fetching https://www.timeanddate.com/weather/philippines/manila\n",
      "[32/142] Fetching https://www.timeanddate.com/weather/new-zealand/auckland\n",
      "[33/142] Fetching https://www.timeanddate.com/weather/australia/melbourne\n",
      "[34/142] Fetching https://www.timeanddate.com/weather/iraq/baghdad\n",
      "[35/142] Fetching https://www.timeanddate.com/weather/mexico/mexico-city\n",
      "[36/142] Fetching https://www.timeanddate.com/weather/thailand/bangkok\n",
      "[37/142] Fetching https://www.timeanddate.com/weather/usa/miami\n",
      "[38/142] Fetching https://www.timeanddate.com/weather/spain/barcelona\n",
      "[39/142] Fetching https://www.timeanddate.com/weather/usa/minneapolis\n",
      "[40/142] Fetching https://www.timeanddate.com/weather/china/beijing\n",
      "[41/142] Fetching https://www.timeanddate.com/weather/belarus/minsk\n",
      "[42/142] Fetching https://www.timeanddate.com/weather/lebanon/beirut\n",
      "[43/142] Fetching https://www.timeanddate.com/weather/uruguay/montevideo\n",
      "[44/142] Fetching https://www.timeanddate.com/weather/serbia/belgrade\n",
      "[45/142] Fetching https://www.timeanddate.com/weather/canada/montreal\n",
      "[46/142] Fetching https://www.timeanddate.com/weather/india/bengaluru\n",
      "[47/142] Fetching https://www.timeanddate.com/weather/russia/moscow\n",
      "[48/142] Fetching https://www.timeanddate.com/weather/germany/berlin\n",
      "[49/142] Fetching https://www.timeanddate.com/weather/india/mumbai\n",
      "[50/142] Fetching https://www.timeanddate.com/weather/colombia/bogota\n",
      "[51/142] Fetching https://www.timeanddate.com/weather/kenya/nairobi\n",
      "[52/142] Fetching https://www.timeanddate.com/weather/usa/boston\n",
      "[53/142] Fetching https://www.timeanddate.com/weather/bahamas/nassau\n",
      "[54/142] Fetching https://www.timeanddate.com/weather/brazil/brasilia\n",
      "[55/142] Fetching https://www.timeanddate.com/weather/india/new-delhi\n",
      "[56/142] Fetching https://www.timeanddate.com/weather/australia/brisbane\n",
      "[57/142] Fetching https://www.timeanddate.com/weather/usa/new-orleans\n",
      "[58/142] Fetching https://www.timeanddate.com/weather/belgium/brussels\n",
      "[59/142] Fetching https://www.timeanddate.com/weather/romania/bucharest\n",
      "[60/142] Fetching https://www.timeanddate.com/weather/norway/oslo\n",
      "[61/142] Fetching https://www.timeanddate.com/weather/hungary/budapest\n",
      "[62/142] Fetching https://www.timeanddate.com/weather/canada/ottawa\n",
      "[63/142] Fetching https://www.timeanddate.com/weather/argentina/buenos-aires\n",
      "[64/142] Fetching https://www.timeanddate.com/weather/france/paris\n",
      "[65/142] Fetching https://www.timeanddate.com/weather/egypt/cairo\n",
      "[66/142] Fetching https://www.timeanddate.com/weather/australia/perth\n",
      "[67/142] Fetching https://www.timeanddate.com/weather/canada/calgary\n",
      "[68/142] Fetching https://www.timeanddate.com/weather/usa/philadelphia\n",
      "[69/142] Fetching https://www.timeanddate.com/weather/australia/canberra\n",
      "[70/142] Fetching https://www.timeanddate.com/weather/usa/phoenix\n",
      "[71/142] Fetching https://www.timeanddate.com/weather/south-africa/cape-town\n",
      "[72/142] Fetching https://www.timeanddate.com/weather/czech-republic/prague\n",
      "[73/142] Fetching https://www.timeanddate.com/weather/venezuela/caracas\n",
      "[74/142] Fetching https://www.timeanddate.com/weather/iceland/reykjavik\n",
      "[75/142] Fetching https://www.timeanddate.com/weather/morocco/casablanca\n",
      "[76/142] Fetching https://www.timeanddate.com/weather/brazil/rio-de-janeiro\n",
      "[77/142] Fetching https://www.timeanddate.com/weather/usa/chicago\n",
      "[78/142] Fetching https://www.timeanddate.com/weather/saudi-arabia/riyadh\n",
      "[79/142] Fetching https://www.timeanddate.com/weather/denmark/copenhagen\n",
      "[80/142] Fetching https://www.timeanddate.com/weather/italy/rome\n",
      "[81/142] Fetching https://www.timeanddate.com/weather/usa/dallas\n",
      "[82/142] Fetching https://www.timeanddate.com/weather/usa/salt-lake-city\n",
      "[83/142] Fetching https://www.timeanddate.com/weather/tanzania/dar-es-salaam\n",
      "[84/142] Fetching https://www.timeanddate.com/weather/usa/san-francisco\n",
      "[85/142] Fetching https://www.timeanddate.com/weather/australia/darwin\n",
      "[86/142] Fetching https://www.timeanddate.com/weather/puerto-rico/san-juan\n",
      "[87/142] Fetching https://www.timeanddate.com/weather/usa/denver\n",
      "[88/142] Fetching https://www.timeanddate.com/weather/el-salvador/san-salvador\n",
      "[89/142] Fetching https://www.timeanddate.com/weather/usa/detroit\n",
      "[90/142] Fetching https://www.timeanddate.com/weather/chile/santiago\n",
      "[91/142] Fetching https://www.timeanddate.com/weather/bangladesh/dhaka\n",
      "[92/142] Fetching https://www.timeanddate.com/weather/dominican-republic/santo-domingo\n",
      "[93/142] Fetching https://www.timeanddate.com/weather/qatar/doha\n",
      "[94/142] Fetching https://www.timeanddate.com/weather/brazil/sao-paulo\n",
      "[95/142] Fetching https://www.timeanddate.com/weather/united-arab-emirates/dubai\n",
      "[96/142] Fetching https://www.timeanddate.com/weather/usa/seattle\n",
      "[97/142] Fetching https://www.timeanddate.com/weather/ireland/dublin\n",
      "[98/142] Fetching https://www.timeanddate.com/weather/south-korea/seoul\n",
      "[99/142] Fetching https://www.timeanddate.com/weather/canada/edmonton\n",
      "[100/142] Fetching https://www.timeanddate.com/weather/china/shanghai\n",
      "[101/142] Fetching https://www.timeanddate.com/weather/germany/frankfurt\n",
      "[102/142] Fetching https://www.timeanddate.com/weather/singapore/singapore\n",
      "[103/142] Fetching https://www.timeanddate.com/weather/guatemala/guatemala\n",
      "[104/142] Fetching https://www.timeanddate.com/weather/bulgaria/sofia\n",
      "[105/142] Fetching https://www.timeanddate.com/weather/canada/halifax\n",
      "[106/142] Fetching https://www.timeanddate.com/weather/canada/st-johns\n",
      "[107/142] Fetching https://www.timeanddate.com/weather/vietnam/hanoi\n",
      "[108/142] Fetching https://www.timeanddate.com/weather/sweden/stockholm\n",
      "[109/142] Fetching https://www.timeanddate.com/weather/zimbabwe/harare\n",
      "[110/142] Fetching https://www.timeanddate.com/weather/fiji/suva\n",
      "[111/142] Fetching https://www.timeanddate.com/weather/cuba/havana\n",
      "[112/142] Fetching https://www.timeanddate.com/weather/australia/sydney\n",
      "[113/142] Fetching https://www.timeanddate.com/weather/finland/helsinki\n",
      "[114/142] Fetching https://www.timeanddate.com/weather/taiwan/taipei\n",
      "[115/142] Fetching https://www.timeanddate.com/weather/hong-kong/hong-kong\n",
      "[116/142] Fetching https://www.timeanddate.com/weather/estonia/tallinn\n",
      "[117/142] Fetching https://www.timeanddate.com/weather/usa/honolulu\n",
      "[118/142] Fetching https://www.timeanddate.com/weather/uzbekistan/tashkent\n",
      "[119/142] Fetching https://www.timeanddate.com/weather/usa/houston\n",
      "[120/142] Fetching https://www.timeanddate.com/weather/honduras/tegucigalpa\n",
      "[121/142] Fetching https://www.timeanddate.com/weather/usa/indianapolis\n",
      "[122/142] Fetching https://www.timeanddate.com/weather/iran/tehran\n",
      "[123/142] Fetching https://www.timeanddate.com/weather/pakistan/islamabad\n",
      "[124/142] Fetching https://www.timeanddate.com/weather/turkey/istanbul\n",
      "[125/142] Fetching https://www.timeanddate.com/weather/canada/toronto\n",
      "[126/142] Fetching https://www.timeanddate.com/weather/indonesia/jakarta\n",
      "[127/142] Fetching https://www.timeanddate.com/weather/canada/vancouver\n",
      "[128/142] Fetching https://www.timeanddate.com/weather/israel/jerusalem\n",
      "[129/142] Fetching https://www.timeanddate.com/weather/austria/vienna\n",
      "[130/142] Fetching https://www.timeanddate.com/weather/south-africa/johannesburg\n",
      "[131/142] Fetching https://www.timeanddate.com/weather/poland/warsaw\n",
      "[132/142] Fetching https://www.timeanddate.com/weather/pakistan/karachi\n",
      "[133/142] Fetching https://www.timeanddate.com/weather/usa/washington-dc\n",
      "[134/142] Fetching https://www.timeanddate.com/weather/nepal/kathmandu\n",
      "[135/142] Fetching https://www.timeanddate.com/weather/canada/winnipeg\n",
      "[136/142] Fetching https://www.timeanddate.com/weather/jamaica/kingston\n",
      "[137/142] Fetching https://www.timeanddate.com/weather/myanmar/yangon\n",
      "[138/142] Fetching https://www.timeanddate.com/weather/congo-demrep/kinshasa\n",
      "[139/142] Fetching https://www.timeanddate.com/weather/croatia/zagreb\n",
      "[140/142] Fetching https://www.timeanddate.com/weather/kiribati/kiritimati\n",
      "[141/142] Fetching https://www.timeanddate.com/weather/switzerland/zurich\n",
      "[142/142] Fetching https://www.timeanddate.com/weather/india/kolkata\n",
      "Saved weather.csv (rows: 142)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "BASE = \"https://www.timeanddate.com\"\n",
    "INDEX = \"https://www.timeanddate.com/weather/\"\n",
    "\n",
    "resp = requests.get(INDEX)\n",
    "resp.raise_for_status()\n",
    "soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "\n",
    "anchors = soup.find_all(\"a\", href=True)\n",
    "city_links = []\n",
    "for a in anchors:\n",
    "    href = a['href']\n",
    "    if href.startswith(\"/weather/\") and href.count('/') >= 2:\n",
    "        \n",
    "        parts = href.split('/')\n",
    "       \n",
    "        if len(parts) >= 4 and parts[2] and parts[3]:\n",
    "            city_links.append(urljoin(BASE, href))\n",
    "\n",
    "seen = set()\n",
    "city_links_unique = []\n",
    "for link in city_links:\n",
    "    if link not in seen:\n",
    "        seen.add(link)\n",
    "        city_links_unique.append(link)\n",
    "\n",
    "print(f\"Found {len(city_links_unique)} candidate city links on index page\")\n",
    "\n",
    "\n",
    "N = 200\n",
    "city_links_unique = city_links_unique[:N]\n",
    "\n",
    "weather_rows = []\n",
    "for idx, link in enumerate(city_links_unique, start=1):\n",
    "    try:\n",
    "        print(f\"[{idx}/{len(city_links_unique)}] Fetching {link}\")\n",
    "        r = requests.get(link, timeout=8)\n",
    "        r.raise_for_status()\n",
    "        s = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "        h1 = s.find(\"h1\")\n",
    "        city_name = h1.text.strip() if h1 else link.split('/')[-1].replace('-', ' ').title()\n",
    "\n",
    "        qlook = s.find(id=\"qlook\")\n",
    "        if qlook:\n",
    "            temp_div = qlook.find(class_=\"h2\")\n",
    "            temp = temp_div.text.strip() if temp_div else None\n",
    " \n",
    "            cond_p = qlook.find(\"p\")\n",
    "            condition = cond_p.text.strip() if cond_p else None\n",
    "        else:\n",
    "          \n",
    "            temp = None\n",
    "            condition = None\n",
    "            \n",
    "            deg = s.find(lambda tag: tag.name in [\"div\", \"span\"] and \"°\" in tag.text)\n",
    "            temp = deg.text.strip() if deg else None\n",
    "            \n",
    "            meta_desc = s.find(\"meta\", {\"name\": \"description\"})\n",
    "            condition = meta_desc[\"content\"].strip() if meta_desc and \"Weather\" in meta_desc.get(\"content\",\"\") else None\n",
    "\n",
    "        weather_rows.append({\"city\": city_name, \"temperature\": temp, \"condition\": condition, \"url\": link})\n",
    "    except Exception as e:\n",
    "        print(\"  -> failed:\", e)\n",
    "    time.sleep(0.2)  \n",
    "\n",
    "df_weather = pd.DataFrame(weather_rows)\n",
    "df_weather.to_csv(\"weather.csv\", index=False)\n",
    "print(\"Saved weather.csv (rows: {})\".format(len(df_weather)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
